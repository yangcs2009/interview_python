
<!-- vim-markdown-toc GFM -->

* [负载均衡算法及主流算法](#负载均衡算法及主流算法)
    * [负载均衡](#负载均衡)
    * [负载均衡分类](#负载均衡分类)
        * [DNS域名解析负载均衡](#dns域名解析负载均衡)
        * [二层负载均衡](#二层负载均衡)
        * [三层负载均衡](#三层负载均衡)
        * [四层负载均衡](#四层负载均衡)
        * [七层负载均衡](#七层负载均衡)
    * [负载均衡算法](#负载均衡算法)
        * [随机（Random）法](#随机random法)
        * [加权随机（Weight Random）法](#加权随机weight-random法)
        * [轮询（Round Robin）法](#轮询round-robin法)
        * [加权轮询（Weight Round Robin）法](#加权轮询weight-round-robin法)
        * [源地址哈希（Hash）法](#源地址哈希hash法)
        * [最小连接数（Least Connections）法](#最小连接数least-connections法)
* [Nginx流量控制](#nginx流量控制)
    * [限流算法](#限流算法)
        * [令牌桶算法](#令牌桶算法)
        * [漏桶算法（leaky bucket）](#漏桶算法leaky-bucket)
    * [Nginx限流算法](#nginx限流算法)
        * [常规配置](#常规配置)
        * [处理突发](#处理突发)
        * [无延迟的排队](#无延迟的排队)

<!-- vim-markdown-toc -->
# 负载均衡算法及主流算法

[负载均衡算法及手段](https://segmentfault.com/a/1190000004492447#articleHeader12)  
[几种简单的负载均衡算法及其Java代码实现](https://www.cnblogs.com/xrq730/p/5154340.html)

## 负载均衡
**负载平衡（Load balancing）** 是一种计算机技术，用来在多个计算机（计算机集群）、网络连接、CPU、磁盘驱动器或其他资源中分配负载，以达到
**最优化资源使用、最大化吞吐率、最小化响应时间、同时避免过载**的目的。   
使用带有负载平衡的多个服务器组件，取代单一的组件，可以 **通过冗余提高可靠性**。负载平衡服务通常是由专用软件和硬件来完成。 主要作用是将大量作业
合理地分摊到多个操作单元上进行执行，用于解决互联网架构中的 **高并发和高可用**的问题。

## 负载均衡分类

**最常用的是四层和七层负载均衡**

[四层、七层负载均衡的区别](https://cloud.tencent.com/developer/article/1082047)  

[四层、七层负载均衡的区别](https://www.jianshu.com/p/fa937b8e6712)

### DNS域名解析负载均衡

![loadbalance_dns.png](img/server/loadbalance_dns.png)

在DNS服务器中应该配置了多个A记录，如：  
      www.apusapp.com IN A 114.100.20.201;  
      www.apusapp.com IN A 114.100.20.202;  
      www.apusapp.com IN A 114.100.20.203;  
因此，每次域名解析请求都会根据对应的负载均衡算法计算出一个不同的IP地址并返回，这样A记录中配置多个服务器就可以构成一个集群，并可以实现负载均衡。

### 二层负载均衡

![loadbalance_2.png](img/server/loadbalance_2.png)

负载均衡服务器对外提供一个VIP（虚IP），集群中不同的机器采用相同IP地址，但是机器的MAC地址不一样。当负载均衡服务器接受到请求之后，通过改写报文的
目标MAC地址的方式将请求转发到目标机器实现负载均衡。

### 三层负载均衡

![loadbalance_3.png](img/server/loadbalance_3.png)

和二层负载均衡类似，负载均衡服务器对外依然提供一个VIP（虚IP），但是集群中不同的机器采用不同的IP地址。当负载均衡服务器接受到请求之后，根据不同的
负载均衡算法，通过IP将请求转发至不同的真实服务器。

### 四层负载均衡

![loadbalance_4.jpg](img/server/loadbalance_4.jpg)

四层负载均衡工作在OSI模型的传输层，由于在传输层，只有TCP/UDP协议，这两种协议中除了包含源IP、目标IP以外，还包含源端口号及目的端口号。四层
负载均衡服务器在接受到客户端请求后，以后通过修改数据包的地址信息（IP+端口号）将流量转发到应用服务器。

### 七层负载均衡

七层负载均衡工作在OSI模型的应用层，应用层协议较多，常用http、radius、dns等。七层负载就可以基于这些协议来负载。这些应用层协议中会包含很多
有意义的内容。比如同一个Web服务器的负载均衡，除了根据IP加端口进行负载外，还可根据七层的URL、浏览器类别、语言来决定是否要进行负载均衡。

对于一般的应用来说，有了Nginx就够了。Nginx可以用于七层负载均衡。但是对于一些大的网站，一般会采用DNS+四层负载+七层负载的方式进行多层次负载均衡。

## 负载均衡算法

### 随机（Random）法
基于概率统计的理论，吞吐量越大，随机算法的效果越接近于轮询算法的效果。

### 加权随机（Weight Random）法
根据后端服务器不同的配置和负载情况来配置不同的权重

### 轮询（Round Robin）法

轮询法的优点在于：试图做到请求转移的绝对均衡。

轮询法的缺点在于：为了做到请求转移的绝对均衡，必须付出相当大的代价，因为为了保证当前轮询的位置变量pos修改的互斥性，需要引入重量级的悲观锁synchronized，
这将会导致该段轮询代码的并发吞吐量发生明显的下降。

### 加权轮询（Weight Round Robin）法
不同的服务器可能机器配置和当前系统的负载并不相同，因此它们的抗压能力也不尽相同，给配置高、负载低的机器配置更高的权重，让其处理更多的请求，
而低配置、高负载的机器，则给其分配较低的权重，降低其系统负载。

实现方式：根据权重的大小，将地址重复地增加到服务器地址列表中，权重越大，该服务器每轮所获得的请求数量越多。比如服务器1权重1，服务器2权重2，
服务器3权重3，则顺序为1-2-2-3-3-3-1-2-2-3-3-3- ......

### 源地址哈希（Hash）法
优点：保证了相同客户端IP地址将会被哈希到同一台后端服务器，直到后端服务器列表变更。根据此特性可以在服务消费者与服务提供者之间建立有状态的session会话。

缺点：除非集群中服务器的非常稳定，基本不会上下线，否则一旦有服务器上线、下线，那么通过源地址哈希算法路由到的服务器是服务器上线、下线前路由到的
服务器的概率非常低，如果是session则取不到session，如果是缓存则可能引发"雪崩"

### 最小连接数（Least Connections）法
以后端服务器的视角来观察系统的负载，而非请求发起方来观察。

根据后端服务器当前的连接情况，动态地选取其中当前积压连接数最少的一台服务器来处理当前请求，尽可能地提高后端服务器的利用效率，将负载合理地分流到每一台机器

# Nginx流量控制

[Nginx如何做流量控制](https://cloud.tencent.com/developer/article/1182207)

[nginx 限流配置](https://www.cnblogs.com/biglittleant/p/8979915.html)

## 限流算法

### 令牌桶算法

![令牌桶算法](img/server/token_limitation.jpg)

算法思想是：

* 令牌以固定速率产生，并缓存到令牌桶中； 
* 令牌桶放满时，多余的令牌被丢弃； 
* 请求要消耗等比例的令牌才能被处理； 
* 令牌不够时，请求被缓存。

### 漏桶算法（leaky bucket）

![漏桶算法](img/server/leak_bucket_limitation.png)

算法思想是：

* 水（请求）从上方倒入水桶，从水桶下方流出（被处理）；
* 来不及流出的水存在水桶中（缓冲），以固定速率流出；
* 水桶满后水溢出（丢弃）。

这个算法的核心是：缓存请求、匀速处理、多余的请求直接丢弃。

从作用上来说，漏桶和令牌桶算法最明显的区别就是是否允许突发流量(burst)的处理，漏桶算法能够强行限制数据的实时传输（处理）速率，对突发流量不做额外处理；
而令牌桶算法能够在限制数据的平均传输速率的同时允许某种程度的突发传输。

## Nginx限流算法

Nginx按请求速率限速模块使用的是 **漏桶算法**，即能够强行保证请求的实时处理速度不会超过设置的阈值。

### 常规配置

“流量限制”配置两个主要的指令，limit_req_zone和limit_req，如下所示：

```
limit_req_zone $binary_remote_addr zone=mylimit:10m rate=10r/s;

server {
    location /login/ {
        limit_req zone=mylimit;

        proxy_pass http://my_upstream;
    }
}
```

limit_req_zone指令定义了流量限制相关的参数，而limit_req指令在出现的上下文中启用流量限制(示例中，对于”/login/”的所有请求)。

limit_req_zone指令通常在HTTP块中定义，使其可在多个上下文中使用，它需要以下三个参数：

* Key - 定义应用限制的请求特性。示例中的Nginx变量$binary_remote_addr，保存客户端IP地址的二进制形式。这意味着，我们可以将每个不同的
IP地址限制到，通过第三个参数设置的请求速率。(使用该变量是因为比字符串形式的客户端IP地址$remote_addr，占用更少的空间)

* Zone - 定义用于存储每个IP地址状态以及被限制请求URL访问频率的 **共享内存区域**。保存在内存共享区域的信息，意味着可以在Nginx的worker进程之间共享。
定义分为两个部分：通过zone=keyword标识区域的名字，以及冒号后面跟区域大小。16000个IP地址的状态信息，大约需要1MB，所以示例中区域可以存储160000个IP地址。

* Rate - 定义最大请求速率。在示例中，速率不能超过每秒10个请求。Nginx实际上以毫秒的粒度来跟踪请求，所以速率限制相当于每100毫秒1个请求。
因为不允许”突发情况”(见下一章节)，这意味着在前一个请求100毫秒内到达的请求将被拒绝。

limit_req_zone指令设置流量限制和共享内存区域的参数，但实际上并不限制请求速率。所以需要通过添加limit_req指令，将流量限制应用在特定的location或者server块。在上面示例中，我们对/login/请求进行流量限制。

现在每个IP地址被限制为每秒只能请求10次/login/，更准确地说，在前一个请求的100毫秒内不能请求该URL。

### 处理突发
如果我们在100毫秒内接收到2个请求，怎么办？对于第二个请求，Nginx将给客户端返回状态码503。这可能并不是我们想要的结果，因为应用本质上趋向于突发性。
相反地，我们希望缓冲任何超额的请求，然后及时地处理它们。我们更新下配置，在limit_req中使用burst参数：

```
location /login/ {
    limit_req zone=mylimit burst=20;
    proxy_pass http://my_upstream;
}
```

burst参数定义了超出zone指定速率的情况下(示例中的mylimit区域，速率限制在每秒10个请求，或每100毫秒一个请求)，客户端还能发起多少请求。上一个请求
100毫秒内到达的请求将会被放入队列，我们将队列大小设置为20。

这意味着，如果从一个给定IP地址发送21个请求，Nginx会立即将第一个请求发送到上游服务器群，然后将余下20个请求放在队列中。然后每100毫秒转发一个排队的请求，
只有当传入请求使队列中排队的请求数超过20时，Nginx才会向客户端返回503。

### 无延迟的排队
配置burst参数将会使通讯更流畅，但是可能会不太实用，因为该配置会使站点看起来很慢。在上面的示例中，队列中的第20个包需要等待2秒才能被转发，此时
返回给客户端的响应可能不再有用。要解决这个情况，可以在burst参数后添加nodelay参数：

```
location /login/ {
    limit_req zone=mylimit burst=20 nodelay;

    proxy_pass http://my_upstream;
}
```

使用nodelay参数，Nginx仍将根据burst参数分配队列中的位置，并应用已配置的速率限制，而不是清理队列中等待转发的请求。相反地，当一个请求到达“太早”时，
只要在队列中能分配位置，Nginx将 **立即转发**这个请求。将队列中的该位置标记为”taken”(占据)，并且不会被释放以供另一个请求使用，直到一段时间后才会被
释放(在这个示例中是，100毫秒后)。

假设如前所述，队列中有20个空位，从给定的IP地址发出的21个请求同时到达。Nginx会立即转发这个21个请求，并且标记队列中占据的20个位置，然后每100毫秒
释放一个位置。如果是25个请求同时到达，Nginx将会立即转发其中的21个请求，标记队列中占据的20个位置，并且返回503状态码来拒绝剩下的4个请求。

现在假设，第一组请求被转发后101毫秒，另20个请求同时到达。队列中只会有一个位置被释放，所以Nginx转发一个请求并返回503状态码来拒绝其他19个请求。
如果在20个新请求到达之前已经过去了501毫秒，5个位置被释放，所以Nginx立即转发5个请求并拒绝另外15个。

效果相当于每秒10个请求的“流量限制”。如果希望不限制两个请求间允许间隔的情况下实施“流量限制”，nodelay参数是很实用的。

注意：对于大部分部署，我们建议使用burst和nodelay参数来配置limit_req指令。
